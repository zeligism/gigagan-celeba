---
_target_: gigagan_pytorch.gigagan_pytorch.GigaGAN
train_upsampler: false
generator:
    dim_capacity: 2
    style_network:
        dim: 16
        depth: 1
        dim_text_latent: 16
    image_size: 64
    dim_max: 128
    num_skip_layers_excite: 1
    unconditional: false
    text_encoder:
      _target_: model.PseudoTextEncoder
      dim_in: ???
      dim: 16
      depth: 1
discriminator:
    dim_capacity: 4
    dim_max: 128
    image_size: 64
    num_skip_layers_excite: 1
    unconditional: false
    text_encoder:
      _target_: model.PseudoTextEncoder
      dim_in: ???
      dim: 16
      depth: 1
# We turn off the kwargs below since were not using CLIP
vision_aided_discriminator: null
vision_aided_divergence_loss_weight: 0.0
generator_contrastive_loss_weight: 0.0
matching_awareness_loss_weight: 0.0
